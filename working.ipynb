{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "import shutil\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import glob\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import pickle\n",
    "import cv2\n",
    "import math\n",
    "import os\n",
    "import random\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_video(images, outvid=None, fps=15, size=None,\n",
    "               is_color=True, format='MP42'):\n",
    "    \"\"\"\n",
    "    Create a video from a list of images.\n",
    " \n",
    "    @param      outvid      output video\n",
    "    @param      images      list of images to use in the video\n",
    "    @param      fps         frame per second\n",
    "    @param      size        size of each frame\n",
    "    @param      is_color    color\n",
    "    @param      format      see http://www.fourcc.org/codecs.php\n",
    "    @return                 see http://opencv-python-tutroals.readthedocs.org/en/latest/py_tutorials/py_gui/py_video_display/py_video_display.html\n",
    " \n",
    "    The function relies on http://opencv-python-tutroals.readthedocs.org/en/latest/.\n",
    "    By default, the video will have the size of the first image.\n",
    "    It will resize every image to this size before adding them to the video.\n",
    "    MODIFIED FROM: http://www.xavierdupre.fr/blog/2016-03-30_nojs.html\n",
    "    \"\"\"\n",
    "    from cv2 import VideoWriter, VideoWriter_fourcc, imread, resize\n",
    "    fourcc = VideoWriter_fourcc(*format)\n",
    "    vid = None\n",
    "    for image in images:\n",
    "        #print(image)\n",
    "        if not os.path.exists(image):\n",
    "            raise FileNotFoundError(image)\n",
    "        img = imread(image)\n",
    "        if vid is None:\n",
    "            if size is None:\n",
    "                size = img.shape[1], img.shape[0]\n",
    "            vid = VideoWriter(outvid, fourcc, float(fps), size, is_color)\n",
    "        if size[0] != img.shape[1] and size[1] != img.shape[0]:\n",
    "            img = resize(img, size)\n",
    "        vid.write(img)\n",
    "    vid.release()\n",
    "    return vid\n",
    "\n",
    "\n",
    "def multiple_sort(value):\n",
    "    \"\"\"sorts zt_data, bt_data, ht_data lists alphabetically and numerically \"\"\"\n",
    "    values = value[0].split(\"/\")\n",
    "    key1 = values[2]\n",
    "    key2 = values[4]\n",
    "    key3 = values[3]\n",
    "    key4 = int(values[5].split('.')[0])\n",
    "    return key1, key2, key3, key4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copyright (c) 2020, NVIDIA Corporation. All rights reserved.\n",
    "#\n",
    "# This work is made available\n",
    "# under the Nvidia Source Code License (1-way Commercial).\n",
    "# To view a copy of this license, visit\n",
    "# https://nvlabs.github.io/Dancing2Music/License.txt\n",
    "import os  \n",
    "import pickle\n",
    "import numpy as np\n",
    "import random\n",
    "import torch.utils.data\n",
    "from torchvision.datasets import ImageFolder\n",
    "#import utils\n",
    "\n",
    "\n",
    "class PoseDataset(torch.utils.data.Dataset):\n",
    "  def __init__(self, data_dir, tolerance=False):\n",
    "    self.data_dir = data_dir\n",
    "    z_fname = '{}/unitList/zumba_unit.txt'.format(data_dir)\n",
    "    b_fname = '{}/unitList/ballet_unit.txt'.format(data_dir)\n",
    "    h_fname = '{}/unitList/hiphop_unit.txt'.format(data_dir)\n",
    "    self.z_data = []\n",
    "    self.b_data = []\n",
    "    self.h_data = []\n",
    "    with open(z_fname, 'r') as f:\n",
    "      for line in f:\n",
    "        self.z_data.append([s for s in line.strip().split(' ')])\n",
    "    with open(b_fname, 'r') as f:\n",
    "      for line in f:\n",
    "        self.b_data.append([s for s in line.strip().split(' ')])\n",
    "    with open(h_fname, 'r') as f:\n",
    "      for line in f:\n",
    "        self.h_data.append([s for s in line.strip().split(' ')])\n",
    "    self.data = [self.z_data, self.b_data, self.h_data]\n",
    "\n",
    "    self.tolerance = tolerance\n",
    "    if self.tolerance:\n",
    "      z3_fname = '{}/unitList/zumba_unitseq3.txt'.format(data_dir)\n",
    "      b3_fname = '{}/unitList/ballet_unitseq3.txt'.format(data_dir)\n",
    "      h3_fname = '{}/unitList/hiphop_unitseq3.txt'.format(data_dir)\n",
    "      z4_fname = '{}/unitList/zumba_unitseq4.txt'.format(data_dir)\n",
    "      b4_fname = '{}/unitList/ballet_unitseq4.txt'.format(data_dir)\n",
    "      h4_fname = '{}/unitList/hiphop_unitseq4.txt'.format(data_dir)\n",
    "      z3_data = []; b3_data = []; h3_data = []; z4_data = []; b4_data = []; h4_data = []\n",
    "      with open(z3_fname, 'r') as f:\n",
    "        for line in f:\n",
    "          z3_data.append([s for s in line.strip().split(' ')])\n",
    "      with open(b3_fname, 'r') as f:\n",
    "        for line in f:\n",
    "          b3_data.append([s for s in line.strip().split(' ')])\n",
    "      with open(h3_fname, 'r') as f:\n",
    "        for line in f:\n",
    "          h3_data.append([s for s in line.strip().split(' ')])\n",
    "      with open(z4_fname, 'r') as f:\n",
    "        for line in f:\n",
    "          z4_data.append([s for s in line.strip().split(' ')])\n",
    "      with open(b4_fname, 'r') as f:\n",
    "        for line in f:\n",
    "          b4_data.append([s for s in line.strip().split(' ')])\n",
    "      with open(h4_fname, 'r') as f:\n",
    "        for line in f:\n",
    "          h4_data.append([s for s in line.strip().split(' ')])\n",
    "      self.zt_data = z3_data + z4_data\n",
    "      self.bt_data = b3_data + b4_data\n",
    "      self.ht_data = h3_data + h4_data\n",
    "      self.t_data = [self.zt_data, self.bt_data, self.ht_data]\n",
    "\n",
    "    self.mean_pose=np.load(data_dir+'/stats/all_onbeat_mean.npy')\n",
    "    self.std_pose=np.load(data_dir+'/stats/all_onbeat_std.npy')\n",
    "\n",
    "  def __getitem__(self, index):\n",
    "    cls = random.randint(0,2)\n",
    "    cls = random.randint(0,1)\n",
    "    if self.tolerance and random.randint(0,9)==0:\n",
    "      index = random.randint(0, len(self.t_data[cls])-1)\n",
    "      path = self.t_data[cls][index][0]\n",
    "      path = os.path.join(self.data_dir, path[5:])\n",
    "      orig_poses = np.load(path)\n",
    "      sel = random.randint(0, orig_poses.shape[0]-1)\n",
    "      orig_poses = orig_poses[sel]\n",
    "    else:\n",
    "      index = random.randint(0, len(self.data[cls])-1)\n",
    "      path = self.data[cls][index][0]\n",
    "      path = os.path.join(self.data_dir, path[5:])\n",
    "      orig_poses = np.load(path)\n",
    "\n",
    "    xjit = np.random.uniform(low=-50, high=50)\n",
    "    yjit = np.random.uniform(low=-20, high=20)\n",
    "    poses = orig_poses.copy()\n",
    "    poses[:,:,0] += xjit\n",
    "    poses[:,:,1] += yjit\n",
    "    xjit = np.random.uniform(low=-50, high=50)\n",
    "    yjit = np.random.uniform(low=-20, high=20)\n",
    "    poses2 = orig_poses.copy()\n",
    "    poses2[:,:,0] += xjit\n",
    "    poses2[:,:,1] += yjit\n",
    "\n",
    "    poses = poses.reshape(poses.shape[0], poses.shape[1]*poses.shape[2])\n",
    "    poses2 = poses2.reshape(poses2.shape[0], poses2.shape[1]*poses2.shape[2])\n",
    "    for i in range(poses.shape[0]):\n",
    "      poses[i] = (poses[i]-self.mean_pose)/self.std_pose\n",
    "      poses2[i] = (poses2[i]-self.mean_pose)/self.std_pose\n",
    "\n",
    "    return torch.Tensor(poses), torch.Tensor(poses2)\n",
    "\n",
    "  def __len__(self):\n",
    "    return len(self.z_data)+len(self.b_data)\n",
    "\n",
    "\n",
    "class MovementAudDataset(torch.utils.data.Dataset):\n",
    "  def __init__(self, data_dir):\n",
    "    self.data_dir = data_dir\n",
    "    z3_fname = '{}/unitList/zumba_unitseq3.txt'.format(data_dir)\n",
    "    b3_fname = '{}/unitList/ballet_unitseq3.txt'.format(data_dir)\n",
    "    h3_fname = '{}/unitList/hiphop_unitseq3.txt'.format(data_dir)\n",
    "    z4_fname = '{}/unitList/zumba_unitseq4.txt'.format(data_dir)\n",
    "    b4_fname = '{}/unitList/ballet_unitseq4.txt'.format(data_dir)\n",
    "    h4_fname = '{}/unitList/hiphop_unitseq4.txt'.format(data_dir)\n",
    "    self.z3_data = []\n",
    "    self.b3_data = []\n",
    "    self.h3_data = []\n",
    "    self.z4_data = []\n",
    "    self.b4_data = []\n",
    "    self.h4_data = []\n",
    "    with open(z3_fname, 'r') as f:\n",
    "      for line in f:\n",
    "        self.z3_data.append([s for s in line.strip().split(' ')])\n",
    "    with open(b3_fname, 'r') as f:\n",
    "      for line in f:\n",
    "        self.b3_data.append([s for s in line.strip().split(' ')])\n",
    "    with open(h3_fname, 'r') as f:\n",
    "      for line in f:\n",
    "        self.h3_data.append([s for s in line.strip().split(' ')])\n",
    "    with open(z4_fname, 'r') as f:\n",
    "      for line in f:\n",
    "        self.z4_data.append([s for s in line.strip().split(' ')])\n",
    "    with open(b4_fname, 'r') as f:\n",
    "      for line in f:\n",
    "        self.b4_data.append([s for s in line.strip().split(' ')])\n",
    "    with open(h4_fname, 'r') as f:\n",
    "      for line in f:\n",
    "        self.h4_data.append([s for s in line.strip().split(' ')])\n",
    "    self.data_3 = [self.z3_data, self.b3_data, self.h3_data]\n",
    "    self.data_4 = [self.z4_data, self.b4_data, self.h4_data]\n",
    "\n",
    "    z_data_root = 'zumba/'\n",
    "    b_data_root = 'ballet/'\n",
    "    h_data_root = 'hiphop/'\n",
    "    self.data_root = [z_data_root, b_data_root, h_data_root ]\n",
    "    self.mean_pose=np.load(data_dir+'/stats/all_onbeat_mean.npy')\n",
    "    self.std_pose=np.load(data_dir+'/stats/all_onbeat_std.npy')\n",
    "    self.mean_aud=np.load(data_dir+'/stats/all_aud_mean.npy')\n",
    "    self.std_aud=np.load(data_dir+'/stats/all_aud_std.npy')\n",
    "\n",
    "  def __getitem__(self, index):\n",
    "    cls = random.randint(0,2)\n",
    "    cls = random.randint(0,1)\n",
    "    isthree = random.randint(0,1)\n",
    "\n",
    "    if isthree == 0:\n",
    "      index = random.randint(0, len(self.data_4[cls])-1)\n",
    "      path = self.data_4[cls][index][0]\n",
    "    else:\n",
    "      index = random.randint(0, len(self.data_3[cls])-1)\n",
    "      path = self.data_3[cls][index][0]\n",
    "    path = os.path.join(self.data_dir, path[5:])\n",
    "    stdpSeq = np.load(path)\n",
    "    vid, cid = path.split('/')[-4], path.split('/')[-3]\n",
    "    #vid, cid = vid_cid[:11], vid_cid[12:]\n",
    "    aud = np.load('{}/{}/{}/{}/aud/c{}_fps15.npy'.format(self.data_dir, self.data_root[cls], vid, cid, cid))\n",
    "\n",
    "    stdpSeq = stdpSeq.reshape(stdpSeq.shape[0], stdpSeq.shape[1], stdpSeq.shape[2]*stdpSeq.shape[3])\n",
    "    for i in range(stdpSeq.shape[0]):\n",
    "      for j in range(stdpSeq.shape[1]):\n",
    "        stdpSeq[i,j] = (stdpSeq[i,j]-self.mean_pose)/self.std_pose\n",
    "    if isthree == 0:\n",
    "      start = random.randint(0,1)\n",
    "      stdpSeq = stdpSeq[start:start+3]\n",
    "\n",
    "    for i in range(aud.shape[0]):\n",
    "      aud[i] = (aud[i]-self.mean_aud)/self.std_aud\n",
    "    aud = aud[:30]\n",
    "    return torch.Tensor(stdpSeq), torch.Tensor(aud)\n",
    "\n",
    "  def __len__(self):\n",
    "    return len(self.z3_data)+len(self.b3_data)+len(self.z4_data)+len(self.b4_data)+len(self.h3_data)+len(self.h4_data)\n",
    "\n",
    "def get_loader(batch_size, shuffle, num_workers, dataset, data_dir, tolerance=False):\n",
    "  if dataset == 0:\n",
    "    a2d = PoseDataset(data_dir, tolerance)\n",
    "  elif dataset == 2:\n",
    "    a2d = MovementAudDataset(data_dir)\n",
    "  data_loader = torch.utils.data.DataLoader(dataset=a2d,\n",
    "                                            batch_size=batch_size,\n",
    "                                            shuffle=shuffle,\n",
    "                                            num_workers=num_workers,\n",
    "                                            )\n",
    "  return data_loader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copyright (c) 2020, NVIDIA Corporation. All rights reserved.\n",
    "#\n",
    "# This work is made available\n",
    "# under the Nvidia Source Code License (1-way Commercial).\n",
    "# To view a copy of this license, visit\n",
    "# https://nvlabs.github.io/Dancing2Music/License.txt\n",
    "\n",
    "import numpy as np\n",
    "import pickle\n",
    "import cv2\n",
    "import math\n",
    "import os\n",
    "import random\n",
    "import tensorflow as tf\n",
    "\n",
    "class Logger(object):\n",
    "  def __init__(self, log_dir):\n",
    "    self.writer = tf.summary.FileWriter(log_dir)\n",
    "\n",
    "  def scalar_summary(self, tag, value, step):\n",
    "    summary = tf.Summary(value=[tf.Summary.Value(tag=tag, simple_value=value)])\n",
    "    self.writer.add_summary(summary, step)\n",
    "\n",
    "def vis(poses, outdir, aud=None):\n",
    "  colors = [[255, 0, 0], [255, 85, 0], [255, 170, 0], [255, 255, 0], [170, 255, 0], [85, 255, 0], [0, 255, 0], \\\n",
    "          [0, 255, 85], [0, 255, 170], [0, 255, 255], [0, 170, 255], [0, 85, 255], [0, 0, 255], [85, 0, 255], \\\n",
    "          [170, 0, 255], [255, 0, 255], [255, 0, 170], [255, 0, 85]]\n",
    "\n",
    "  # find connection in the specified sequence, center 29 is in the position 15\n",
    "  limbSeq = [[2,3], [2,6], [3,4], [4,5], [6,7], [7,8], [2,9], [9,10], \\\n",
    "           [10,11], [2,12], [12,13], [13,14], [2,1], [1,15], [15,17], \\\n",
    "           [1,16], [16,18], [3,17], [6,18]]\n",
    "\n",
    "  neglect = [14,15,16,17]\n",
    "\n",
    "  for t in range(poses.shape[0]):\n",
    "    #break\n",
    "    canvas = np.ones((256,500,3), np.uint8)*255\n",
    "\n",
    "    thisPeak = poses[t]\n",
    "    for i in range(18):\n",
    "      if i in neglect:\n",
    "        continue\n",
    "      if thisPeak[i,0] == -1:\n",
    "        continue\n",
    "      cv2.circle(canvas, tuple(thisPeak[i,0:2].astype(int)), 4, colors[i], thickness=-1)\n",
    "\n",
    "    for i in range(17):\n",
    "      limbid = np.array(limbSeq[i])-1\n",
    "      if limbid[0] in neglect or limbid[1] in neglect:\n",
    "        continue\n",
    "      X = thisPeak[[limbid[0],limbid[1]], 1]\n",
    "      Y = thisPeak[[limbid[0],limbid[1]], 0]\n",
    "      if X[0] == -1 or Y[0]==-1 or X[1]==-1 or Y[1]==-1:\n",
    "        continue\n",
    "      stickwidth = 4\n",
    "      cur_canvas = canvas.copy()\n",
    "      mX = np.mean(X)\n",
    "      mY = np.mean(Y)\n",
    "      #print(X, Y, limbid)\n",
    "      length = ((X[0] - X[1]) ** 2 + (Y[0] - Y[1]) ** 2) ** 0.5\n",
    "      angle = math.degrees(math.atan2(X[0] - X[1], Y[0] - Y[1]))\n",
    "      polygon = cv2.ellipse2Poly((int(mY),int(mX)), (int(length/2), stickwidth), int(angle), 0, 360, 1)\n",
    "      #print(i, n, int(mY), int(mX), limbid, X, Y)\n",
    "      cv2.fillConvexPoly(cur_canvas, polygon, colors[i])\n",
    "      canvas = cv2.addWeighted(canvas, 0.4, cur_canvas, 0.6, 0)\n",
    "    if aud is not None:\n",
    "      if aud[:,t] == 1:\n",
    "        cv2.circle(canvas, (30, 30), 20, (0,0,255), -1)\n",
    "        #canvas = cv2.copyMakeBorder(canvas,10,10,10,10,cv2.BORDER_CONSTANT,value=[255,0,0])\n",
    "    cv2.imwrite(os.path.join(outdir, 'frame{0:03d}.png'.format(t)),canvas)\n",
    "\n",
    "def vis2(poses, outdir, fibeat):\n",
    "  colors = [[255, 0, 0], [255, 85, 0], [255, 170, 0], [255, 255, 0], [170, 255, 0], [85, 255, 0], [0, 255, 0], \\\n",
    "          [0, 255, 85], [0, 255, 170], [0, 255, 255], [0, 170, 255], [0, 85, 255], [0, 0, 255], [85, 0, 255], \\\n",
    "          [170, 0, 255], [255, 0, 255], [255, 0, 170], [255, 0, 85]]\n",
    "\n",
    "  # find connection in the specified sequence, center 29 is in the position 15\n",
    "  limbSeq = [[2,3], [2,6], [3,4], [4,5], [6,7], [7,8], [2,9], [9,10], \\\n",
    "           [10,11], [2,12], [12,13], [13,14], [2,1], [1,15], [15,17], \\\n",
    "           [1,16], [16,18], [3,17], [6,18]]\n",
    "\n",
    "\n",
    "  neglect = [14,15,16,17]\n",
    "\n",
    "  ibeat = cv2.imread(fibeat);\n",
    "  ibeat = cv2.resize(ibeat, (500,200))\n",
    "\n",
    "  for t in range(poses.shape[0]):\n",
    "    subibeat = ibeat.copy()\n",
    "    canvas = np.ones((256+200,500,3), np.uint8)*255\n",
    "    canvas[256:,:,:] = subibeat\n",
    "\n",
    "    overlay = canvas.copy()\n",
    "    cv2.rectangle(overlay, (int(500/poses.shape[0]*(t+1)),256),(500,256+200), (100,100,100), -1)\n",
    "    cv2.addWeighted(overlay, 0.4, canvas, 1-0.4, 0, canvas)\n",
    "    thisPeak = poses[t]\n",
    "    for i in range(18):\n",
    "      if i in neglect:\n",
    "        continue\n",
    "      if thisPeak[i,0] == -1:\n",
    "        continue\n",
    "      cv2.circle(canvas, tuple(thisPeak[i,0:2].astype(int)), 4, colors[i], thickness=-1)\n",
    "\n",
    "    for i in range(17):\n",
    "      limbid = np.array(limbSeq[i])-1\n",
    "      if limbid[0] in neglect or limbid[1] in neglect:\n",
    "        continue\n",
    "      X = thisPeak[[limbid[0],limbid[1]], 1]\n",
    "      Y = thisPeak[[limbid[0],limbid[1]], 0]\n",
    "      if X[0] == -1 or Y[0]==-1 or X[1]==-1 or Y[1]==-1:\n",
    "        continue\n",
    "      stickwidth = 4\n",
    "      cur_canvas = canvas.copy()\n",
    "      mX = np.mean(X)\n",
    "      mY = np.mean(Y)\n",
    "      #print(X, Y, limbid)\n",
    "      length = ((X[0] - X[1]) ** 2 + (Y[0] - Y[1]) ** 2) ** 0.5\n",
    "      angle = math.degrees(math.atan2(X[0] - X[1], Y[0] - Y[1]))\n",
    "      polygon = cv2.ellipse2Poly((int(mY),int(mX)), (int(length/2), stickwidth), int(angle), 0, 360, 1)\n",
    "      #print(i, n, int(mY), int(mX), limbid, X, Y)\n",
    "      cv2.fillConvexPoly(cur_canvas, polygon, colors[i])\n",
    "      canvas = cv2.addWeighted(canvas, 0.4, cur_canvas, 0.6, 0)\n",
    "    cv2.imwrite(os.path.join(outdir, 'frame{0:03d}.png'.format(t)),canvas)\n",
    "\n",
    "def vis_single(pose, outfile):\n",
    "  colors = [[255, 0, 0], [255, 85, 0], [255, 170, 0], [255, 255, 0], [170, 255, 0], [85, 255, 0], [0, 255, 0], \\\n",
    "          [0, 255, 85], [0, 255, 170], [0, 255, 255], [0, 170, 255], [0, 85, 255], [0, 0, 255], [85, 0, 255], \\\n",
    "          [170, 0, 255], [255, 0, 255], [255, 0, 170], [255, 0, 85]]\n",
    "\n",
    "  # find connection in the specified sequence, center 29 is in the position 15\n",
    "  limbSeq = [[2,3], [2,6], [3,4], [4,5], [6,7], [7,8], [2,9], [9,10], \\\n",
    "           [10,11], [2,12], [12,13], [13,14], [2,1], [1,15], [15,17], \\\n",
    "           [1,16], [16,18], [3,17], [6,18]]\n",
    "\n",
    "  neglect = [14,15,16,17]\n",
    "\n",
    "  for t in range(1):\n",
    "    #break\n",
    "    canvas = np.ones((256,500,3), np.uint8)*255\n",
    "\n",
    "    thisPeak = pose\n",
    "    for i in range(18):\n",
    "      if i in neglect:\n",
    "        continue\n",
    "      if thisPeak[i,0] == -1:\n",
    "        continue\n",
    "      cv2.circle(canvas, tuple(thisPeak[i,0:2].astype(int)), 4, colors[i], thickness=-1)\n",
    "\n",
    "    for i in range(17):\n",
    "      limbid = np.array(limbSeq[i])-1\n",
    "      if limbid[0] in neglect or limbid[1] in neglect:\n",
    "        continue\n",
    "      X = thisPeak[[limbid[0],limbid[1]], 1]\n",
    "      Y = thisPeak[[limbid[0],limbid[1]], 0]\n",
    "      if X[0] == -1 or Y[0]==-1 or X[1]==-1 or Y[1]==-1:\n",
    "        continue\n",
    "      stickwidth = 4\n",
    "      cur_canvas = canvas.copy()\n",
    "      mX = np.mean(X)\n",
    "      mY = np.mean(Y)\n",
    "      length = ((X[0] - X[1]) ** 2 + (Y[0] - Y[1]) ** 2) ** 0.5\n",
    "      angle = math.degrees(math.atan2(X[0] - X[1], Y[0] - Y[1]))\n",
    "      polygon = cv2.ellipse2Poly((int(mY),int(mX)), (int(length/2), stickwidth), int(angle), 0, 360, 1)\n",
    "      cv2.fillConvexPoly(cur_canvas, polygon, colors[i])\n",
    "      canvas = cv2.addWeighted(canvas, 0.4, cur_canvas, 0.6, 0)\n",
    "    cv2.imwrite(outfile,canvas)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"/data/Dancing2Music/data/\"\n",
    "tolerance = True\n",
    "if tolerance:\n",
    "  z3_fname = '{}/unitList/zumba_unitseq3.txt'.format(data_dir)\n",
    "  b3_fname = '{}/unitList/ballet_unitseq3.txt'.format(data_dir)\n",
    "  h3_fname = '{}/unitList/hiphop_unitseq3.txt'.format(data_dir)\n",
    "  z4_fname = '{}/unitList/zumba_unitseq4.txt'.format(data_dir)\n",
    "  b4_fname = '{}/unitList/ballet_unitseq4.txt'.format(data_dir)\n",
    "  h4_fname = '{}/unitList/hiphop_unitseq4.txt'.format(data_dir)\n",
    "  z3_data = []; b3_data = []; h3_data = []; z4_data = []; b4_data = []; h4_data = []\n",
    "  with open(z3_fname, 'r') as f:\n",
    "    for line in f:\n",
    "      z3_data.append([s for s in line.strip().split(' ')])\n",
    "  with open(b3_fname, 'r') as f:\n",
    "    for line in f:\n",
    "      b3_data.append([s for s in line.strip().split(' ')])\n",
    "  with open(h3_fname, 'r') as f:\n",
    "    for line in f:\n",
    "      h3_data.append([s for s in line.strip().split(' ')])\n",
    "  with open(z4_fname, 'r') as f:\n",
    "    for line in f:\n",
    "      z4_data.append([s for s in line.strip().split(' ')])\n",
    "  with open(b4_fname, 'r') as f:\n",
    "    for line in f:\n",
    "      b4_data.append([s for s in line.strip().split(' ')])\n",
    "  with open(h4_fname, 'r') as f:\n",
    "    for line in f:\n",
    "      h4_data.append([s for s in line.strip().split(' ')])\n",
    "  zt_data = z3_data + z4_data\n",
    "  bt_data = b3_data + b4_data\n",
    "  ht_data = h3_data + h4_data\n",
    "  t_data = [zt_data, bt_data, ht_data]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
